<!DOCTYPE HTML>
<!--
	Phantom by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>

<head>
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=G-YFBP31Y1CZ"></script>
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag() { dataLayer.push(arguments); }
		gtag('js', new Date());

		gtag('config', 'G-YFBP31Y1CZ');
	</script>

	<title>MagCIL</title>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
	<link rel="stylesheet" href="assets/css/main.css" />
	<noscript>
		<link rel="stylesheet" href="assets/css/noscript.css" />
	</noscript>
</head>

<body class="is-preload">
	<!-- Wrapper -->
	<div id="wrapper">

		<!-- Header -->
		<header id="header">
			<div class="inner">

				<!-- Logo -->
				<a href="index.html" class="logo">
					<span class="symbol"><img src="images/logo.png" alt="" /></span><span class="title">Multimedia <br>
						Analysis <br>Group<br>II&T DEMOKRITOS</span>
				</a>

				<!-- Nav -->
				<nav>
					<ul>
						<li><a href="#menu">Menu</a></li>
					</ul>
				</nav>

			</div>
		</header>

		<!-- Menu -->
		<nav id="menu">
			<h2>Menu</h2>
			<ul>
				<li><a href="index.html">Home</a></li>
				<li><a href="about.html">About Us</a></li>
				<li><a href="deep_audio_api.html">Deep Audio API</a></li>
				<li><a href="solutions.html">Multimodal ML Solutions</a></li>
				<li><a href="projects.html">Projects</a></li>
				<li><a href="code.html">Open-source code and data</a></li>
				<li><a href="demos.html">Demos</a></li>
				<li><a href="pub.html">Selected publications</a></li>
				<li><a href="tech.html">Technology</a></li>
				<li><a href="education.html">Education</a></li>
			</ul>
		</nav>

		<!-- Main -->
		<div id="main">
			<div class="inner">
				<h1>Selected Publications</h1>

				<!-- Text -->
				<section>
					<div class="table-wrapper">
						<table>
							<tbody>

								<tr>
									<td>Nikou, C., & Giannakopoulos, T.</td>
									<td>Contrastive and Transfer Learning for Effective Audio Fingerprinting through a
										Real-World Evaluation Protocol</td>
									<td>IJMSTA, 7(1), 68-82 (2025)</td>
									<td></td>
								</tr>

								<tr>
									<td>Sgouropoulos, C., Nikou, C., Vlachos, S., Theiou, V., Foukanelis, C., &
										Giannakopoulos, T.</td>
									<td>Prototypical Contrastive Learning For Improved Few-Shot Audio</td>
									<td>IEEE MLSP (2025)</td>
									<td></td>
								</tr>

								<tr>
									<td>Nikou, C., Theiou, V., Vlachos, S., Sgouropoulos, C., Sgouropoulos, D., &
										Giannakopoulos, T.</td>
									<td>On the Robustness of State-of-the-Art Transformers for Sound Event
										Classification Against Black Box Adversarial Attacks</td>
									<td>2025 EUSIPCO. IEEE (2025)</td>
									<td></td>
								</tr>

								<tr>
									<td>Koromilas, P., Bouritsas, G., Giannakopoulos, T., Nicolaou, M., & Panagakis, Y.
									</td>
									<td>Bridging Mini-Batch and Asymptotic Analysis in Contrastive Learning: From
										InfoNCE to Kernel-Based Losses</td>
									<td>Forty-first International Conference on Machine Learning (2024)</td>
									<td></td>
								</tr>

								<tr>
									<td>Mitsou, A., Petrogianni, A., Vakalaki, E. A., Nikou, C., Psallidas, T., &
										Giannakopoulos, T.</td>
									<td>A multimodal dataset for electric guitar playing technique recognition</td>
									<td>Data in Brief, Vol 52 (2024)</td>
									<td></td>
								</tr>

								<tr>
									<td>Kaliosis, P., Eleftheriou, S., Nikou, C., & Giannakopoulos, T.</td>
									<td>A self-supervised learning approach for detecting non-psychotic relapses using
										wearable-based digital phenotyping</td>
									<td>2024 IEEE ICASSPW. IEEE (2024)</td>
									<td></td>
								</tr>

								<tr>
									<td>Petrogianni, A., Kapelonis, L., Antoniou, N., Eleftheriou, S., Mitseas, P.,
										Sgouropoulos, D., Katsamanis, N., Giannakopoulos, T., & Narayanan, S.</td>
									<td>RobuSER: A robustness Benchmark for Speech Emotion Recognition</td>
									<td>2024 12th International Conference on Affective Computing and Intelligent
										Interaction (ACII) (pp. 1-7). IEEE (2024)</td>
									<td></td>
								</tr>

								<tr>
									<td>Eleftheriadis, K., Gini, M., Manousakas, M., Diapouli, E., Vratolis, S.,
										Papagiannis, S., Zografou, O., Giannakopoulos, T., Konstantopoulos, S., Mocnik,
										G., & Drinovec, L.</td>
									<td>MItigating Transport-Related Air Pollution in Europe: The MI-TRAP project</td>
									<td>The European Aerosol Conference (2024)</td>
									<td></td>
								</tr>

								<tr>
									<td>Sgouropoulos, D., Mitseas, P., Eleftheriou, S., Giannakopoulos, T., Petrogianni,
										A., Kapelonis, L., Antoniou, N., Katsamanis, A., & Narayanan, S.</td>
									<td>Emotion-aware speech popularity prediction: a use-case on TED talks</td>
									<td>2024 12th International Conference on Affective Computing and Intelligent
										Interaction (ACII). IEEE (2024)</td>
									<td></td>
								</tr>

								<tr>
									<td>Gkritzali, E., Kaliosis, P., Galanaki, S., Palogiannidi, E., & Giannakopoulos,
										T.</td>
									<td>Greek2MathTex: A Greek Speech-to-Text Framework for LaTeX Equations Generation
									</td>
									<td>13th Helenic Conference on AI, SETN 2024, Piraeus, Greece, September 11-13,
										2024. Proceedings 4 (2024)</td>
									<td></td>
								</tr>

								<tr>
									<td>Melistas, T., Kapelonis, L., Antoniou, N., Mitseas, P., Sgouropoulos, D.,
										Giannakopoulos, T., Katsamanis, A., Narayanan, S., & Demokritos, N.C.S.R.</td>
									<td>Cross-lingual features for alzheimer's dementia detection from speech</td>
									<td>Proc. INTERSPEECH (pp. 3008-3012) (2023)</td>
									<td></td>
								</tr>

								<tr>
									<td>Christopoulos, D., Chatzi, E., Sofianopoulos, G., Patiniotaki, E., Eleftheriou,
										S., Koromilas, P., Kaliosis, P., Gkouti, N., Giannakopoulos, T., Petridis, K., &
										Sismanidou, E.</td>
									<td>Smart Subs Subtitling App for Watching Live Virtual Dome Performances</td>
									<td>2023 SMAP. IEEE (2023)</td>
									<td></td>
								</tr>

								<tr>
									<td>Bochalis, C., Vargas, C. D., Jarvis, E. D., & Giannakopoulos, T.</td>
									<td>Unsupervised Temporal Analysis of Mouse Vocalizations</td>
									<td>2023 IEEE Conference on Computational Intelligence in Bioinformatics and
										Computational Biology (CIBCB) (pp. 1-8). IEEE (2023)</td>
									<td></td>
								</tr>

								<tr>
									<td>Petrogianni, A., Vassilakis, D., Klampanos, I. A., Giannakopoulos, T., &
										Andreopoulou, A.</td>
									<td>Jazz Mapping: An Advanced Framework for Solo Analysis and Discovery in Jazz
										Music</td>
									<td>Audio Engineering Society Convention 155 (2023)</td>
									<td></td>
								</tr>

								<tr>
									<td>Koromilas, P., Nicolaou, M. A., Giannakopoulos, T., & Panagakis, Y.</td>
									<td>MMATR: A Lightweight Approach for Multimodal Sentiment Analysis Based on Tensor
										Methods</td>
									<td>ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal
										Processing (ICASSP) (pp. 1-5). IEEE (2023)</td>
									<td></td>
								</tr>

								<tr>
									<td>Antoniou, N., Katsamanis, A., Giannakopoulos, T., & Narayanan, S.</td>
									<td>Designing and Evaluating Speech Emotion Recognition Systems: A reality check
										case study with IEMOCAP</td>
									<td>ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal
										Processing (ICASSP) (pp. 1-5). IEEE (2023)</td>
									<td></td>
								</tr>

								<tr>
									<td>Alygizakis, N., Giannakopoulos, T., Τhomaidis, N. S., & Slobodnik, J.</td>
									<td> Detecting the sources of chemicals in the Black Sea using non-target screening
										and deep learning convolutional neural networks</td>
									<td>Science of The Total Environment, 157554 (2022), </td>
									<td><a href="https://www.sciencedirect.com/science/article/abs/pii/S0048969722046526"
											target="_blank">html</a></td>
								</tr>

								<tr>
									<td>Petrogianni, A., Koromilas, P., & Giannakopoulos, T.</td>
									<td> Film Shot Type Classification Based on Camera Movement Styles</td>
									<td>Iberian Conference on Pattern Recognition and Image Analysis (pp. 602-615), 2022
									</td>
									<td><a href="https://link.springer.com/chapter/10.1007/978-3-031-04881-4_48"
											target="_blank">html</a></td>
								</tr>


								<tr>
									<td>M. Moutti, S. Eleftheriou, P. Koromilas, T. Giannakopoulos</td>
									<td> A Dataset for Speech Emotion Recognition in Greek Theatrical Plays</td>
									<td>13th Conference on Language Resources and Evaluation (LREC 2022), pages
										1040–1046</td>
									<td><a href="http://www.lrec-conf.org/proceedings/lrec2022/pdf/2022.lrec-1.111.pdf"
											target="_blank">pdf</a></td>
								</tr>

								<tr>
									<td>Tsitos, A. C., Dagioglou, M., & Giannakopoulos, T.</td>
									<td> Real-time feasibility of a human intention method evaluated through a
										competitive human-robot reaching game</td>
									<td>2022 ACM/IEEE International Conference on Human-Robot Interaction (pp.
										1080-1084) </td>
									<td><a href="https://dl.acm.org/doi/abs/10.5555/3523760.3523939"
											target="_blank">html</a></td>
								</tr>


								<tr>
									<td>Dagioglou, M., Soulounias, N., & Giannakopoulos, T.</td>
									<td> Object Size Prediction from Hand Movement Using a Single RGB Sensor</td>
									<td>International Conference on Human-Computer Interaction (pp. 369-386), 2022 </td>
									<td><a href="https://link.springer.com/chapter/10.1007/978-3-031-05643-7_24"
											target="_blank">html</a></td>
								</tr>

								<tr>
									<td>Touros, G., & Giannakopoulos, T.</td>
									<td>Video soundtrack evaluation with machine learning: Data availability, feature
										extraction, and classification</td>
									<td>Advances in Speech and Music Technology (2022)</td>
									<td></td>
								</tr>

								<tr>
									<td>Moutti, M., Eleftheriou, S., Koromilas, P., & Giannakopoulos, T.</td>
									<td>Cross linguistic speech emotion recognition using CNNs: a use-case in Greek
										Theatrical Data</td>
									<td>Proceedings of the 15th International Conference on PErvasive Technologies
										Related to Assistive Environments (pp. 662-667) (2022)</td>
									<td></td>
								</tr>

								<tr>
									<td>Zouros, M., & Giannakopoulos, T.</td>
									<td>Photography Style Analysis using Convolutional Neural Networks</td>
									<td>2022 SITIS. IEEE (2022)</td>
									<td></td>
								</tr>

								<tr>
									<td>Stoumpou, V., Vargas, C. D., Schade, P. F., Boyd, J. L., Giannakopoulos, T., &
										Jarvis, E. D.</td>
									<td>Analysis of Mouse Vocal Communication (AMVOC): a deep, unsupervised method for
										rapid detection, analysis and classification of ultrasonic vocalisations</td>
									<td>Bioacoustics, 1-31 (2022)</td>
									<td></td>
								</tr>

								<tr>
									<td>Geroulanos, A., & Giannakopoulos, T.</td>
									<td>Emotion Recognition in Music Using Deep Neural Networks</td>
									<td>Advances in Speech and Music Technology: Computational Aspects and Applications.
										Cham: Springer International Publishing, 193-213 (2022)</td>
									<td></td>
								</tr>

								<tr>
									<td>Papaioannou, C., Valiantzas, I., Giannakopoulos, T., Kaliakatsos Papakostas, M.,
										& Potamianos, A.</td>
									<td>A Dataset for Greek Traditional and Folk Music: Lyra</td>
									<td>23rd International Society for Music Information Retrieval Conference (ISMIR
										2022) (2022)</td>
									<td></td>
								</tr>

								<tr>
									<td>Chatziagapi, A., Sgouropoulos, D., Karouzos, C., Melistas, T., Giannakopoulos,
										T., Katsamanis, A., & Narayanan, S.</td>
									<td>Audio and ASR-based Filled Pause Detection</td>
									<td>2022 10th International Conference on Affective Computing and Intelligent
										Interaction (ACII) (pp. 1-7). IEEE (2022)</td>
									<td></td>
								</tr>

								<tr>
									<td>Koromilas, P., & Giannakopoulos, T.</td>
									<td> Deep multimodal emotion recognition on human speech: A review</td>
									<td>Applied Sciences, 11(17), 7962 (2021).</td>
									<td><a href="https://www.mdpi.com/2076-3417/11/17/7962/pdf" target="_blank">pdf</a>
									</td>
								</tr>

								<tr>
									<td>Paraskevoudis, K., & Giannakopoulos, T.</td>
									<td> Instrument Playing Technique Recognition: A Greek Music Use Case</td>
									<td>In Worldwide Music Conference (pp. 124-136). Springer (2021)</td>
									<td><a href="https://www.springerprofessional.de/en/instrument-playing-technique-recognition-a-greek-music-use-case/19058676"
											target="_blank">html</a></td>
								</tr>

								<tr>
									<td>Psallidas, T., Koromilas, P., Giannakopoulos, T., & Spyrou, E.</td>
									<td> Multimodal Summarization of User-Generated Videos</td>
									<td>Applied Sciences, 11(11), 5260. (2021)</td>
									<td><a href="https://www.mdpi.com/2076-3417/11/11/5260/pdf" target="_blank">pdf</a>
									</td>
								</tr>

								<tr>
									<td>Eleftheriou, S., Koromilas, P., & Giannakopoulos, T.</td>
									<td>Automatic Assessment of Speaking Skills Using Aural and Textual Information</td>
									<td>Proceedings of The Fourth International Conference on Natural Language and
										Speech Processing (ICNLSP 2021) (pp. 166-1) (2021)</td>
									<td></td>
								</tr>

								<tr>
									<td>Mitsou, A., Spyrou, E., & Giannakopoulos, T.</td>
									<td>Multimodal Workplace Monitoring for Human Activity Recognition</td>
									<td>25th Pan-Hellenic Conference on Informatics (pp. 206-211) (2021)</td>
									<td></td>
								</tr>

								<tr>
									<td>Melistas, T., & Giannakopoulos, T.</td>
									<td>Lyrics and Vocal Melody Generation conditioned on Accompaniment</td>
									<td>Proceedings of the 2nd Workshop on NLP for Music and Spoken Audio (NLP4MusA)
										(2021)</td>
									<td></td>
								</tr>


								<tr>
									<td>Psallidas, T., Mitsou, A., Pikramenos, G., Spyrou, E., & Giannakopoulos, T.</td>
									<td>ARCHEO: A Dataset for Sound Event Detection in Areas of Touristic Interest</td>
									<td>2020 15th International Workshop on Semantic and Social Media Adaptation and
										Personalization (SMA (pp. 1-6). IEEE.</td>
									<td><a href="https://ieeexplore.ieee.org/abstract/document/9248467"
											target="_blank">html</a></td>
								</tr>

								<tr>
									<td>Giannakopoulos, T., Orfanidi, M., & Perantonis, S. </td>
									<td>Athens Urban Soundscape (ATHUS): A Dataset for Urban Soundscape Quality
										Recognition. </td>
									<td>In International Conference on Multimedia Modeling (pp. 338-348). Springer,
										Cham., 2019</td>
									<td><a href="https://www.researchgate.net/profile/Theodoros_Giannakopoulos/publication/329513490_Athens_Urban_Soundscape_ATHUS_A_Dataset_for_Urban_Soundscape_Quality_Recognition_25th_International_Conference_MMM_2019_Thessaloniki_Greece_January_8-11_2019_Proceedings_Part_I/links/5f989eada6fdccfd7b84acc0/Athens-Urban-Soundscape-ATHUS-A-Dataset-for-Urban-Soundscape-Quality-Recognition-25th-International-Conference-MMM-2019-Thessaloniki-Greece-January-8-11-2019-Proceedings-Part-I.pdf"
											target="_blank">pdf</a></td>
								</tr>


								<tr>
									<td>Pikramenos, G., Smyrnis, G., Vernikos, I., Konidaris, T., Spyrou, E., &
										Perantonis, S </td>
									<td>Sentiment Analysis from Sound Spectrograms via Soft BoVW and Temporal Structure
										Modelling. </td>
									<td>In ICPRAM (pp. 361-369) 2019</td>
									<td><a href="https://www.researchgate.net/profile/Ioannis_Vernikos/publication/339923046_Sentiment_Analysis_from_Sound_Spectrograms_via_Soft_BoVW_and_Temporal_Structure_Modelling/links/5f00be6d45851550508adf08/Sentiment-Analysis-from-Sound-Spectrograms-via-Soft-BoVW-and-Temporal-Structure-Modelling.pdf"
											target="_blank">pdf</a></td>
								</tr>

								<tr>
									<td>Giannakopoulos, T., Dimopoulos, S., Pantazopoulos, G., Chatziagapi, A.,
										Sgouropoulos, D., Katsamanis, A., Potamianos, A., & Narayanan, S.</td>
									<td>Using Oliver API for emotion-aware movie content characterization</td>
									<td>2019 CBMI. IEEE (2019)</td>
									<td></td>
								</tr>

								<tr>
									<td>Giannakopoulos, T., & Perantonis, S.</td>
									<td>Recognizing the quality of urban sound recordings using hand-crafted and deep
										audio features</td>
									<td>Proceedings of the 12th ACM International Conference on PErvasive Technologies
										Related to Assistive Environments (2019)</td>
									<td></td>
								</tr>

								<tr>
									<td>Paraskevopoulos, G., Spyrou, E., Sgouropoulos, D., Giannakopoulos, T., &
										Mylonas, P.</td>
									<td>Real-Time Arm Gesture Recognition Using 3D Skeleton Joint Data</td>
									<td>Algorithms, 12(5), 108 (2019)</td>
									<td></td>
								</tr>

								<tr>
									<td>Giannakopoulos, T., Konstantopoulos, S., Siantikos, G., & Karkaletsis, V.</td>
									<td>A System of Recognition Services for Clinical Assessment</td>
									<td>RADIO–Robots in Assisted Living (pp. 7-18). Springer (2019)</td>
									<td></td>
								</tr>

								<tr>
									<td>Chatziagapi, A., Paraskevopoulos, G., Sgouropoulos, D., Pantazopoulos, G.,
										Nikandrou, M., Giannakopoulos, T., Katsamanis, A., Potamianos, A., & Narayanan,
										S.</td>
									<td>Data Augmentation Using GANs for Speech Emotion Recognition</td>
									<td>Proc. Interspeech 2019, 171-175 (2019)</td>
									<td></td>
								</tr>

								<tr>
									<td>Paraskevopoulos, G., Tzinis, E., Ellinas, N., Giannakopoulos, T., & Potamianos,
										A.</td>
									<td>Unsupervised Low-Rank Representations for Speech Emotion Recognition</td>
									<td>Proc. Interspeech 2019, 939-943 (2019)</td>
									<td></td>
								</tr>

								<tr>
									<td>Papakostas, Michalis, and Theodoros Giannakopoulos</td>
									<td>Speech-music discrimination using deep visual feature extractors</td>
									<td>Expert Systems with Applications 114 (2018): 334-344.</td>
									<td><a href="https://www.researchgate.net/profile/Michalis_Papakostas/publication/321038622_Speech-Music_Discrimination_Using_Deep_Visual_Feature_Extractors/links/5a09f3b90f7e9bb949f9692e/Speech-Music-Discrimination-Using-Deep-Visual-Feature-Extractors.pdf"
											target="_blank">pdf</a></td>
								</tr>

								<tr>
									<td>Sarafianos, N., Giannakopoulos, T., Nikou, C., & Kakadiaris, I. A. </td>
									<td>Curriculum learning of visual attribute clusters for multi-task classification
									</td>
									<td>Pattern Recognition, 80, 94-108., 2018</td>
									<td><a href="https://arxiv.org/pdf/1709.06664" target="_blank">pdf</a></td>
								</tr>

								<tr>
									<td>Bougiatiotis, Konstantinos, and Theodoros Giannakopoulos</td>
									<td>Enhanced movie content similarity based on textual, auditory and visual
										information.</td>
									<td>Expert Systems with Applications 96 (2018): 86-102.</td>
									<td><a href="https://arxiv.org/pdf/1711.03889" target="_blank">pdf</a></td>
								</tr>

								<tr>
									<td>Papakostas, M., Tsiakas, K., Giannakopoulos, T., & Makedon, F. </td>
									<td>Towards predicting task performance from EEG signals</td>
									<td>2017 IEEE International Conference on Big Data (Big Data) (pp. 4423-4425)</td>
									<td><a href="https://ieeexplore.ieee.org/iel7/8241556/8257893/08258478.pdf?casa_token=MDkQBH-zBWgAAAAA:J470z_2HnTh0Mu8s1HDAoTnItuy7lODSFESuVyAbaI-e8ahXjpiolBZ-p6IkX30ZnG9K0cEWPzEA"
											target="_blank">pdf</a></td>
								</tr>

								<tr>
									<td>Sarafianos, N., Giannakopoulos, T., Nikou, C., & Kakadiaris, I. A.</td>
									<td>Curriculum learning for multi-task classification of visual attributes</td>
									<td>2017 In Proceedings of the IEEE International Conference on Computer Vision
										Workshops (pp. 2608-2615)</td>
									<td><a href="http://openaccess.thecvf.com/content_ICCV_2017_workshops/papers/w38/Sarafianos_Curriculum_Learning_for_ICCV_2017_paper.pdf"
											target="_blank">pdf</a></td>
								</tr>


								<tr>
									<td>Korakakis, M., Spyrou, E., Mylonas, P., & Perantonis, S.</td>
									<td>Exploiting social media information toward a context-aware recommendation system
									</td>
									<td>Social Network Analysis and Mining, 7(1), 42., 2017</td>
									<td><a href="https://idp.springer.com/authorize/casa?redirect_uri=https://link.springer.com/article/10.1007/s13278-017-0459-9&casa_token=7rtvhCnkIZoAAAAA:ubet_l_uv_47ekFflGKPHv_ehcFOtQi8nR2yuXvX9wd0YLLQwzvCY20bdE2_JIAWySaRgsTVd4s28sm7"
											target="_blank">html</a></td>
								</tr>

								<tr>
									<td>Giannakopoulos, T., & Konstantopoulos, S.</td>
									<td>Daily Activity Recognition based on Meta-classification of Low-level Audio
										Events</td>
									<td>Proceedings of ICT4AWE2017, ISBN: 978-989-758-251-6 (2017)</td>
									<td></td>
								</tr>

								<tr>
									<td>Giannakopoulos, T., Konstantopoulos, S., Siantikos, G., & Karkaletsis, V.</td>
									<td>Design for a System of Multimodal Interconnected ADL Recognition Services</td>
									<td>Components and Services for IoT Platforms, pp. 323-333. Springer International
										Publishing (2017)</td>
									<td></td>
								</tr>

								<tr>
									<td>Papakostas, M., Siantikos, G., Giannakopoulos, T., Spyrou, E., & Sgouropoulos,
										D.</td>
									<td>Recognizing Emotional States Using Speech Information</td>
									<td>GeNeDis 2016 (pp. 155-164). Springer, Cham (2017)</td>
									<td></td>
								</tr>


								<tr>
									<td>Giannakopoulos, T., & Siantikos, G.</td>
									<td>A ROS Framework for Audio-Based Activity Recognition</td>
									<td>Proceedings of the 9th ACM International Conference on PErvasive Technologies
										Related to Assistive Environments (PETRA 2016) (2016)</td>
									<td></td>
								</tr>

								<tr>
									<td>Nivolianitou, Z. S., Koromila, I. A., & Giannakopoulos, T.</td>
									<td>Bayesian network to predict environmental risk of a possible ship accident</td>
									<td>International Journal of Risk Assessment and Management, 19(3), 228-239 (2016)
									</td>
									<td></td>
								</tr>

								<tr>
									<td>Papakostas, M., Giannakopoulos, T., & Makedon, F.</td>
									<td>Short-term Recognition of Human Activities using Convolutional Neural Networks
									</td>
									<td>2016 International Conference on Signal-Image Technology & Internet Based
										Systems (SITIS). IEEE (2016)</td>
									<td></td>
								</tr>

								<tr>
									<td>Smailis, C., Sarafianos, N., Giannakopoulos, T., & Perantonis, S.</td>
									<td>Fusing Active Orientation Models and Mid-term Audio Features for Automatic
										Depression Estimation</td>
									<td>Proceedings of the 9th ACM International Conference on PErvasive Technologies
										Related to Assistive Environments (PETRA 2016) (2016)</td>
									<td></td>
								</tr>

								<tr>
									<td>Bougiatiotis, K., & Giannakopoulos, T.</td>
									<td>Content Representation and Similarity of Movies based on Topic Extraction from
										Subtitles</td>
									<td>Proceedings of the 9th Hellenic Conference on Artificial Intelligence. ACM
										(2016)</td>
									<td></td>
								</tr>

								<tr>
									<td>Sarafianos, N., Giannakopoulos, T., & Petridis, S.</td>
									<td>Audio-visual speaker diarization using fisher linear semi-discriminant analysis.
									</td>
									<td>Multimedia Tools and Applications, 75(1), 115-130, 2016</td>
									<td><a href="https://idp.springer.com/authorize/casa?redirect_uri=https://link.springer.com/content/pdf/10.1007/s11042-014-2274-x.pdf&casa_token=xPmU0Ki7RTgAAAAA:IjJb3duOUaITvyFIFwT5jMpbl0hRBgeKRyP-oZ74J6pipcsx_7CE4ecuSWHdmjOz4lehZhnwXbAoHk8g"
											target="_blank">pdf</a></td>
								</tr>

								<tr>
									<td>Spyrou, E., & Mylonas, P. </td>
									<td>Analyzing Flickr metadata to extract location-based information and semantically
										organize its photo content.</td>
									<td>Neurocomputing, 172, 114-133., 2016</td>
									<td>
										<a href="http://www.academia.edu/download/51474726/2016_Analyzing_Flickr_metadata_to_extract_location-based_information.pdf"
											target="_blank">html</a>
									</td>
								</tr>

								<tr>
									<td>Giannakopoulos Theodoros</td>
									<td>pyaudioanalysis: An open-source python library for audio signal analysis.</td>
									<td>PloS one 10.12 (2015): e0144610.</td>
									<td><a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0144610g"
											target="_blank">html</a></td>
								</tr>

								<tr>
									<td>Giannakopoulos, T., Siantikos, G., Perantonis, S., Votsi, N. E., & Pantis, J.
									</td>
									<td>Automatic soundscape quality estimation using audio analysis</td>
									<td>Proceedings of the 8th ACM International Conference on PErvasive Technologies
										Related to Assistive Environments (p. 19) (2015)</td>
									<td></td>
								</tr>

								<tr>
									<td>Giannakopoulos, T., Gyftakis, S., Charou, E., Perantonis, S., Nivolianitou, Z.,
										Koromila, I., & Makrygiorgos, A.</td>
									<td>Long-term marine traffic monitoring for environmental safety in the aegean sea
									</td>
									<td>International Archives of the Photogrammetry, Remote Sensing Spatial Information
										Sciences (2015)</td>
									<td></td>
								</tr>

								<tr>
									<td>Petridis, S., Giannakopoulos, T., & Spyropoulos, C. D.</td>
									<td>A Low Cost Pupillometry Approach</td>
									<td>International Journal of E-Health and Medical Communications (IJEHMC), 6(4),
										49-61 (2015)</td>
									<td></td>
								</tr>

								<tr>
									<td>Sgouropoulos, D., Giannakopoulos, T., Siantikos, G., Spyrou, E., & Perantonis,
										S.</td>
									<td>Detection of Clothes Change Fusing Color, Texture, Edge and Depth Information
									</td>
									<td>E-Business and Telecommunications, vol. 554 of Communications in Computer and
										Information Science, pp. 383-392, Springer (2015)</td>
									<td></td>
								</tr>

								<tr>
									<td>Petridis, S., Giannakopoulos, T., & Perantonis, S.</td>
									<td>Unobtrusive Low-Cost Physiological Monitoring Using Visual Information</td>
									<td>Handbook of Research on Innovations in the Diagnosis and Treatment of Dementia,
										306 (2015)</td>
									<td></td>
								</tr>

								<tr>
									<td>Sgouropoulos, D., Spyrou, E., Siantikos, G., & Giannakopoulos, T.</td>
									<td>Counting and tracking people in a smart room: An IoT approach</td>
									<td>Semantic and Social Media Adaptation and Personalization (SMAP), 2015 10th
										International Workshop on (pp. 1-5). IEEE (2015)</td>
									<td></td>
								</tr>

								<tr>
									<td>Siantikos, G., Sgouropoulos, D., Giannakopoulos, T., & Spyrou, E.</td>
									<td>Fusing multiple audio sensors for acoustic event detection</td>
									<td>Image and Signal Processing and Analysis (ISPA), 2015 9th International
										Symposium on (pp. 265-269). IEEE (2015)</td>
									<td></td>
								</tr>

								<tr>
									<td>Koromila, I., Nivolianitou, Z., Perantonis, S., Giannakopoulos, T., Charou, E.,
										Gyftakis, S., & Spyrou, K.</td>
									<td>Environmental Risk Assessment for the Aegean Sea</td>
									<td>11th International Conference on Marine Navigation and Safety of Sea
										Transportation (TransNav 2015) (2015)</td>
									<td></td>
								</tr>

								<tr>
									<td>Giannakopoulos, T., & Pikrakis, A.</td>
									<td>Introduction to audio analysis: a MATLAB® approach</td>
									<td>Academic Press (2014)</td>
									<td></td>
								</tr>

								<tr>
									<td>Giannakopoulos, T., Smailis, C., Perantonis, S. J., & Spyropoulos, C. D.</td>
									<td>Realtime depression estimation using mid-term audio features</td>
									<td>AI-AM/NetMed@ECAI (2014)</td>
									<td></td>
								</tr>

								<tr>
									<td>Giannakopoulos, T., & Petridis, S.</td>
									<td>Fisher linear semi-discriminant analysis for speaker diarization</td>
									<td>IEEE TASLP 20.7 (2012): 1913-1922</td>
									<td></td>
								</tr>

								<tr>
									<td>Giannakopoulos, T., & Petridis, S.</td>
									<td>Detection and clustering of musical audio parts using Fisher linear
										semi-discriminant analysis</td>
									<td>2012 EUSIPCO. IEEE (2012)</td>
									<td></td>
								</tr>

								<tr>
									<td>Giannakopoulos, T., Makris, A., Kosmopoulos, D., Perantonis, S., & Theodoridis,
										S.</td>
									<td>Audio-visual fusion for detecting violent scenes in videos</td>
									<td>2010</td>
									<td></td>
								</tr>


							</tbody>
						</table>
					</div>




				</section>




			</div>
		</div>

		<!-- Footer -->
		<footer id="footer">
			<div class="inner">
				<section>
					<h2>Contact</h2>
					<ul class="icons">
						<li><a href="https://www.linkedin.com/company/75063337/" class="icon brands style2 fa-linkedin"
								target="_blank"><span class="label"></span></a></li>
						<li><a href="mailto:tyiannak@gmail.com" class="icon solid style2 fa-envelope"><span
									class="label">Email</span></a></li>
					</ul>
				</section>
				<ul class="copyright">
					<li>&copy; 2022 Theodoros Giannakopoulos. All rights reserved</li>
					<li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
				</ul>
			</div>
		</footer>

	</div>

	<!-- Scripts -->
	<script src="assets/js/jquery.min.js"></script>
	<script src="assets/js/browser.min.js"></script>
	<script src="assets/js/breakpoints.min.js"></script>
	<script src="assets/js/util.js"></script>
	<script src="assets/js/main.js"></script>

</body>

</html>